{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0cJJefQYd5v4PlzGd1urE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/I51GMA/mlproject/blob/main/HMM_POS_Tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from numba import njit\n",
        "nltk.download('brown')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCele34D0YMg",
        "outputId": "48d095ce-db4b-4415-f326-f821946786e0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load word and tag data from Brown corpus\n",
        "word_and_tag = list(brown.tagged_words())\n",
        "\n",
        "# Extract unique words and POS tags\n",
        "words = list(set([word for word, _ in word_and_tag]))\n",
        "pos_tags = list(set([tag for _, tag in word_and_tag]))\n",
        "\n",
        "# Mapping words and POS tags to indices\n",
        "word_to_index = {word: idx for idx, word in enumerate(words)}\n",
        "tag_to_index = {tag: idx for idx, tag in enumerate(pos_tags)}\n",
        "\n",
        "# Convert word-tag pairs into their corresponding indices before passing to JIT function\n",
        "indexed_word_tag_pairs = [\n",
        "    (word_to_index[word], tag_to_index[tag])\n",
        "    for word, tag in word_and_tag\n",
        "]\n",
        "\n",
        "@njit  # Use Numba to optimize the computation\n",
        "def make_sparse_matrix(indexed_word_tag_pairs, num_words, num_tags):\n",
        "    sparse_matrix = np.zeros((num_words, num_tags))\n",
        "    for word_idx, tag_idx in indexed_word_tag_pairs:\n",
        "        sparse_matrix[word_idx, tag_idx] += 1\n",
        "    return sparse_matrix"
      ],
      "metadata": {
        "id": "x61W5SDi0uRd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnm = True\n",
        "\n",
        "sparse_matrix_path = './sparse_matrix.csv'\n",
        "\n",
        "# If the CSV exists or we need to reconstruct the matrix\n",
        "if not os.path.exists(sparse_matrix_path) or bnm:\n",
        "    sparse_matrix = make_sparse_matrix(indexed_word_tag_pairs, len(words), len(pos_tags))\n",
        "\n",
        "    df = pd.DataFrame(sparse_matrix, columns=pos_tags, dtype=np.int32)\n",
        "    df.insert(0, 'Words', words)\n",
        "    df.to_csv(sparse_matrix_path, index=False)\n",
        "else:\n",
        "    df = pd.read_csv(sparse_matrix_path)"
      ],
      "metadata": {
        "id": "gtu46AXL2g-G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_transition_matrix_and_initial_probs(tagged_sentences, tag_to_index):\n",
        "    num_tags = len(tag_to_index)\n",
        "\n",
        "    # Initializing the transition matrix and initial probabilities array\n",
        "    transition_matrix = np.zeros((num_tags, num_tags), dtype=np.float64)\n",
        "    initial_probs = np.zeros(num_tags, dtype=np.float64)\n",
        "\n",
        "    for sentence in tagged_sentences:\n",
        "        # Get the index of the first tag in the sentence for initial probabilities\n",
        "        initial_probs[tag_to_index[sentence[0][1]]] += 1\n",
        "\n",
        "        for n in range(len(sentence) - 1):\n",
        "            tag_i = sentence[n][1]\n",
        "            tag_j = sentence[n + 1][1]\n",
        "\n",
        "            transition_matrix[tag_to_index[tag_i], tag_to_index[tag_j]] += 1\n",
        "\n",
        "    # Normalize the transition matrix row-wise, handling cases where the row sums to 0\n",
        "    row_sums = np.sum(transition_matrix, axis=1, keepdims=True)\n",
        "    row_sums[row_sums == 0] = 1  # Avoid division by zero for tags with no transitions\n",
        "    transition_matrix /= row_sums\n",
        "\n",
        "    # Normalize initial probabilities, handling zero-sum case\n",
        "    if np.sum(initial_probs) > 0:\n",
        "        initial_probs /= np.sum(initial_probs)\n",
        "\n",
        "    return transition_matrix, initial_probs"
      ],
      "metadata": {
        "id": "tw0xVyP77nsp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating transition matrix and initial probabilities array\n",
        "A, Pi = make_transition_matrix_and_initial_probs(brown.tagged_sents(categories='news'), tag_to_index)"
      ],
      "metadata": {
        "id": "Cj1Lv6h58fNh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the emission probabilities\n",
        "B = df.iloc[:, 1:].values.astype(np.float64).T\n",
        "B /= np.sum(B, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "0ooG3z8s842B"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "@jit(nopython=True)\n",
        "def viterbi_algorithm_log(state_transition_matrix, initial_probs, emission_matrix, observations):\n",
        "    \"\"\"A unique Viterbi algorithm for finding the most likely sequence of hidden states using log probabilities.\n",
        "\n",
        "    Args:\n",
        "        state_transition_matrix (np.ndarray): State transition probability matrix (I x I)\n",
        "        initial_probs (np.ndarray): Initial state distribution (I)\n",
        "        emission_matrix (np.ndarray): Emission matrix (I x K)\n",
        "        observations (np.ndarray): Observation sequence (length N)\n",
        "\n",
        "    Returns:\n",
        "        optimal_states (np.ndarray): Optimal state sequence (length N)\n",
        "        log_probability_matrix (np.ndarray): Log probability matrix\n",
        "        backtrack_matrix (np.ndarray): Backtrack matrix for finding the optimal path\n",
        "    \"\"\"\n",
        "    num_states = state_transition_matrix.shape[0]  # I: Number of states\n",
        "    sequence_length = len(observations)            # N: Length of observation sequence\n",
        "\n",
        "    # Tiny value to prevent log(0) errors\n",
        "    tiny_value = np.finfo(np.float64).tiny\n",
        "\n",
        "    # Take logarithms of all probabilities (handling zero probabilities)\n",
        "    log_transition_matrix = np.log(state_transition_matrix + tiny_value)\n",
        "    log_initial_probs = np.log(initial_probs + tiny_value)\n",
        "    log_emission_matrix = np.log(emission_matrix + tiny_value)\n",
        "\n",
        "    # Initialize log probability and backtrack matrices\n",
        "    log_probability_matrix = np.zeros((num_states, sequence_length), dtype=np.float64)\n",
        "    backtrack_matrix = np.zeros((num_states, sequence_length - 1), dtype=np.int32)\n",
        "\n",
        "    # Initialize first column of the log probability matrix\n",
        "    log_probability_matrix[:, 0] = log_initial_probs + log_emission_matrix[:, observations[0]]\n",
        "\n",
        "    # Dynamic programming: fill in the log probability and backtrack matrices\n",
        "    for t in range(1, sequence_length):\n",
        "        for current_state in range(num_states):\n",
        "            log_transition_values = log_transition_matrix[:, current_state] + log_probability_matrix[:, t - 1]\n",
        "            log_probability_matrix[current_state, t] = np.max(log_transition_values) + log_emission_matrix[current_state, observations[t]]\n",
        "            backtrack_matrix[current_state, t - 1] = np.argmax(log_transition_values)\n",
        "\n",
        "    # Backtracking to find the optimal state sequence\n",
        "    optimal_states = np.zeros(sequence_length, dtype=np.int32)\n",
        "    optimal_states[-1] = np.argmax(log_probability_matrix[:, -1])\n",
        "\n",
        "    for t in range(sequence_length - 2, -1, -1):\n",
        "        optimal_states[t] = backtrack_matrix[optimal_states[t + 1], t]\n",
        "\n",
        "    return optimal_states, log_probability_matrix, backtrack_matrix"
      ],
      "metadata": {
        "id": "F0nhQPR-4WK0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = 203\n",
        "test_sent = brown.sents(categories='news')[r]\n",
        "\n",
        "O = []\n",
        "correct_tag_seq = []\n",
        "test_tagged = brown.tagged_sents(categories='news')[r]\n",
        "\n",
        "for word, tag in test_tagged:\n",
        "    if word in word_to_index:\n",
        "        O.append(word_to_index[word])\n",
        "        if tag in tag_to_index:\n",
        "            correct_tag_seq.append(tag_to_index[tag])\n",
        "\n",
        "O = np.array(O, dtype=np.int32)\n",
        "\n",
        "# Performing Viterbi decoding using the Viterbi function\n",
        "opt_state_seq, log_prob_trellis, backtrack_matrix = viterbi_algorithm_log(A, Pi, B, O)\n",
        "\n",
        "print('Observation sequence:   O  = ', O)\n",
        "print('Optimal state sequence: S  = ', opt_state_seq)\n",
        "print('Correct state sequence: S* = ', correct_tag_seq)\n",
        "print(\"Do they match: \", correct_tag_seq == list(opt_state_seq))\n",
        "\n",
        "guessed_tags = [pos_tags[i] for i in opt_state_seq]\n",
        "test_tagged_words = [word for word, _ in test_tagged if word in word_to_index]\n",
        "test_result_df = pd.DataFrame(index=test_tagged_words, columns=['Correct', 'Guessed'], data=zip(test_tagged, guessed_tags)).T\n",
        "\n",
        "print('The sentence: ', test_sent)\n",
        "print(test_result_df.iloc[:, (test_result_df.nunique() != 1).values])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuytWWC69SCF",
        "outputId": "563812e1-0b92-4c85-f64f-86b82377d8f4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation sequence:   O  =  [17724 15056 34685 22511 10822   191  3607  3463 15922 42426  4217 16795\n",
            " 14637 11131   636 52778 32302 53709 24256 21729  5357]\n",
            "Optimal state sequence: S  =  [359 190 309 325 338 402 309  71 429 439 424 402 345  89 345 157 456  61\n",
            " 345 300  13]\n",
            "Correct state sequence: S* =  [359, 190, 309, 325, 338, 402, 309, 71, 429, 439, 424, 402, 345, 115, 345, 157, 456, 61, 345, 300, 13]\n",
            "Do they match:  False\n",
            "The sentence:  ['It', 'is', 'impossible', 'to', 'get', 'a', 'fair', 'trial', 'when', 'some', 'of', 'the', 'defendants', 'made', 'statements', 'involving', 'themselves', 'and', 'others', \"''\", '.']\n",
            "                It         is        impossible        to        get        a  \\\n",
            "Correct  (It, PPS)  (is, BEZ)  (impossible, JJ)  (to, TO)  (get, VB)  (a, AT)   \n",
            "Guessed        PPS        BEZ                JJ        TO         VB       AT   \n",
            "\n",
            "               fair        trial         when         some  ...        the  \\\n",
            "Correct  (fair, JJ)  (trial, NN)  (when, WRB)  (some, DTI)  ...  (the, AT)   \n",
            "Guessed          JJ           NN          WRB          DTI  ...         AT   \n",
            "\n",
            "                defendants         made         statements         involving  \\\n",
            "Correct  (defendants, NNS)  (made, VBD)  (statements, NNS)  (involving, VBG)   \n",
            "Guessed                NNS          VBN                NNS               VBG   \n",
            "\n",
            "                 themselves        and         others        ''       .  \n",
            "Correct  (themselves, PPLS)  (and, CC)  (others, NNS)  ('', '')  (., .)  \n",
            "Guessed                PPLS         CC            NNS        ''       .  \n",
            "\n",
            "[2 rows x 21 columns]\n"
          ]
        }
      ]
    }
  ]
}